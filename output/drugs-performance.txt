(a)
*********************************************
**** Gaussian NB, try 1 ****
*********************************************
(b)
  4   0   0   0   0
  0   5   0   0   0
  0   0   4   0   0
  0   0   0  16   0
  2   0   4   0  15
(c)
              precision    recall  f1-score   support

       drugY       0.67      1.00      0.80         4
       drugC       1.00      1.00      1.00         5
       drugX       0.50      1.00      0.67         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      0.71      0.83        21

    accuracy                           0.88        50
   macro avg       0.83      0.94      0.86        50
weighted avg       0.93      0.88      0.89        50
              precision    recall  f1-score   support

       drugY       0.67      1.00      0.80         4
       drugC       1.00      1.00      1.00         5
       drugX       0.50      1.00      0.67         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      0.71      0.83        21
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree , try 1 ****
*********************************************
(b)
  4   0   0   0   0
  0   5   0   0   0
  0   0   4   0   0
  0   0   0  16   0
  0   0   0   0  21
(c)
              precision    recall  f1-score   support

       drugY       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      1.00      1.00        21

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50
              precision    recall  f1-score   support

       drugY       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      1.00      1.00        21
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt , try 1 ****
*********************************************
(b)
  4   0   0   0   0
  0   5   0   0   0
  0   0   4   0   0
  0   0   0  16   0
  0   0   0   0  21
(c)
              precision    recall  f1-score   support

       drugY       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      1.00      1.00        21

    accuracy                           1.00        50
   macro avg       1.00      1.00      1.00        50
weighted avg       1.00      1.00      1.00        50
              precision    recall  f1-score   support

       drugY       1.00      1.00      1.00         4
       drugC       1.00      1.00      1.00         5
       drugX       1.00      1.00      1.00         4
       drugA       1.00      1.00      1.00        16
       drugb       1.00      1.00      1.00        21
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron , try 1 ****
*********************************************
(b)
  0   2   0   2   0
  0   5   0   0   0
  0   2   0   1   1
  0   5   0   7   4
  0   0   0   5  16
(c)
              precision    recall  f1-score   support

       drugY       0.00      0.00      0.00         4
       drugC       0.36      1.00      0.53         5
       drugX       0.00      0.00      0.00         4
       drugA       0.47      0.44      0.45        16
       drugb       0.76      0.76      0.76        21

    accuracy                           0.56        50
   macro avg       0.32      0.44      0.35        50
weighted avg       0.51      0.56      0.52        50
              precision    recall  f1-score   support

       drugY       0.00      0.00      0.00         4
       drugC       0.36      1.00      0.53         5
       drugX       0.00      0.00      0.00         4
       drugA       0.47      0.44      0.45        16
       drugb       0.76      0.76      0.76        21
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP , try 1 ****
*********************************************
(b)
  0   0   0   2   2
  0   0   0   5   0
  0   0   0   2   2
  0   0   0   8   8
  0   0   0   0  21
(c)
              precision    recall  f1-score   support

       drugY       0.00      0.00      0.00         4
       drugC       0.00      0.00      0.00         5
       drugX       0.00      0.00      0.00         4
       drugA       0.47      0.50      0.48        16
       drugb       0.64      1.00      0.78        21

    accuracy                           0.58        50
   macro avg       0.22      0.30      0.25        50
weighted avg       0.42      0.58      0.48        50
              precision    recall  f1-score   support

       drugY       0.00      0.00      0.00         4
       drugC       0.00      0.00      0.00         5
       drugX       0.00      0.00      0.00         4
       drugA       0.47      0.50      0.48        16
       drugb       0.64      1.00      0.78        21
(d)
Accuracy   : 0.58
Macro    F1: 0.2525252525252525
Weighted F1: 0.4818181818181818


(a)
*********************************************
**** Top_MLP , try 1 ****
*********************************************
(b)
  3   1   0   0   0
  0   5   0   0   0
  0   0   2   2   0
  0   0   0  13   3
  0   0   0   0  21
(c)
              precision    recall  f1-score   support

       drugY       1.00      0.75      0.86         4
       drugC       0.83      1.00      0.91         5
       drugX       1.00      0.50      0.67         4
       drugA       0.87      0.81      0.84        16
       drugb       0.88      1.00      0.93        21

    accuracy                           0.88        50
   macro avg       0.92      0.81      0.84        50
weighted avg       0.89      0.88      0.87        50
              precision    recall  f1-score   support

       drugY       1.00      0.75      0.86         4
       drugC       0.83      1.00      0.91         5
       drugX       1.00      0.50      0.67         4
       drugA       0.87      0.81      0.84        16
       drugb       0.88      1.00      0.93        21
(d)
Accuracy   : 0.88
Macro    F1: 0.8409886887306243
Weighted F1: 0.8732009495880465





Step 8

(a)
*********************************************
**** Gaussian NB, try 1****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 1****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 1****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 1****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 1****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.24022727272727273
Weighted F1: 0.46072727272727276


(a)
*********************************************
**** Top_MLP try 1****
*********************************************
(d)
Accuracy   : 0.84
Macro    F1: 0.7706941585763466
Weighted F1: 0.8227007158339558





Step 8

(a)
*********************************************
**** Gaussian NB, try 2****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 2****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 2****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 2****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 2****
*********************************************
(d)
Accuracy   : 0.6
Macro    F1: 0.26437291897891235
Weighted F1: 0.5022419533851277


(a)
*********************************************
**** Top_MLP try 2****
*********************************************
(d)
Accuracy   : 0.78
Macro    F1: 0.6068511198945982
Weighted F1: 0.742266139657444





Step 8

(a)
*********************************************
**** Gaussian NB, try 3****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 3****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 3****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 3****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 3****
*********************************************
(d)
Accuracy   : 0.58
Macro    F1: 0.2525252525252525
Weighted F1: 0.4818181818181818


(a)
*********************************************
**** Top_MLP try 3****
*********************************************
(d)
Accuracy   : 0.78
Macro    F1: 0.5918614718614718
Weighted F1: 0.7431688311688311





Step 8

(a)
*********************************************
**** Gaussian NB, try 4****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 4****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 4****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 4****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 4****
*********************************************
(d)
Accuracy   : 0.58
Macro    F1: 0.2525252525252525
Weighted F1: 0.4818181818181818


(a)
*********************************************
**** Top_MLP try 4****
*********************************************
(d)
Accuracy   : 0.76
Macro    F1: 0.5798489553924336
Weighted F1: 0.7219198193111237





Step 8

(a)
*********************************************
**** Gaussian NB, try 5****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 5****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 5****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 5****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 5****
*********************************************
(d)
Accuracy   : 0.58
Macro    F1: 0.2525252525252525
Weighted F1: 0.4818181818181818


(a)
*********************************************
**** Top_MLP try 5****
*********************************************
(d)
Accuracy   : 0.8
Macro    F1: 0.6326086956521739
Weighted F1: 0.7601449275362319





Step 8

(a)
*********************************************
**** Gaussian NB, try 6****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 6****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 6****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 6****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 6****
*********************************************
(d)
Accuracy   : 0.54
Macro    F1: 0.22741935483870965
Weighted F1: 0.43887096774193546


(a)
*********************************************
**** Top_MLP try 6****
*********************************************
(d)
Accuracy   : 0.8
Macro    F1: 0.6326086956521739
Weighted F1: 0.7601449275362319





Step 8

(a)
*********************************************
**** Gaussian NB, try 7****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 7****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 7****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 7****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 7****
*********************************************
(d)
Accuracy   : 0.54
Macro    F1: 0.22741935483870965
Weighted F1: 0.43887096774193546


(a)
*********************************************
**** Top_MLP try 7****
*********************************************
(d)
Accuracy   : 0.82
Macro    F1: 0.702457757296467
Weighted F1: 0.80078955453149





Step 8

(a)
*********************************************
**** Gaussian NB, try 8****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 8****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 8****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 8****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 8****
*********************************************
(d)
Accuracy   : 0.58
Macro    F1: 0.2525252525252525
Weighted F1: 0.4818181818181818


(a)
*********************************************
**** Top_MLP try 8****
*********************************************
(d)
Accuracy   : 0.8
Macro    F1: 0.6563623613413234
Weighted F1: 0.7614841259722044





Step 8

(a)
*********************************************
**** Gaussian NB, try 9****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 9****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 9****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 9****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 9****
*********************************************
(d)
Accuracy   : 0.54
Macro    F1: 0.22736842105263158
Weighted F1: 0.4374736842105263


(a)
*********************************************
**** Top_MLP try 9****
*********************************************
(d)
Accuracy   : 0.82
Macro    F1: 0.6684848484848486
Weighted F1: 0.782909090909091





Step 8

(a)
*********************************************
**** Gaussian NB, try 10****
*********************************************
(d)
Accuracy   : 0.88
Macro    F1: 0.86
Weighted F1: 0.8873333333333333


(a)
*********************************************
**** Decision Tree try 10****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Top-dt try 10****
*********************************************
(d)
Accuracy   : 1.0
Macro    F1: 1.0
Weighted F1: 1.0


(a)
*********************************************
**** Perceptron try 10****
*********************************************
(d)
Accuracy   : 0.56
Macro    F1: 0.3479666909208505
Weighted F1: 0.5171477079796264


(a)
*********************************************
**** Base_MLP try 10****
*********************************************
(d)
Accuracy   : 0.54
Macro    F1: 0.22741935483870965
Weighted F1: 0.43887096774193546


(a)
*********************************************
**** Top_MLP try 10****
*********************************************
(d)
Accuracy   : 0.8
Macro    F1: 0.6468511198945983
Weighted F1: 0.774266139657444
